data:
  train:
    type: coco_detect
    name: train_data
    data_transforms:
      - type: detect_transform.mosaic
        apply_prob: 1
      - type: detect_transform.copy_paste
      - type: detect_transform.flip
      - type: detect_transform.random_warp
        scale_factor: [0.102, 1.898]
        shear_factor: 0.602
      - type: repeat
      - type: detect_transform.mixup
      - type: albumentations
      - type: agument_hsv
        h_gain: 0.0138
        s_gain: 0.664
        v_gain: 0.464
      - type: to_tensor
      - type: detect_transform.generate_sparse_anchored_boxcls
        anchor_thr: 2.91
      - type: collect
        inputs: ['img']
        targets:
          [
            'target_cxywh',
            'target_cij',
            'target_cls',
            'target_anc_idx',
            'target_anc',
            'target_cnt',
          ]
        target_batching: concat
    data_loader:
      batch_size: 16 # 64
      num_workers: 2
      shuffle: true
    data_params:
      shuffle: true
  val:
    type: coco_detect
    name: val_data
    data_transforms:
      - type: to_tensor
      - type: detect_transform.generate_sparse_anchored_boxcls
        anchor_thr: 2.91
      - type: collect
        inputs: ['img']
        targets:
          [
            'target_cxywh',
            'target_cij',
            'target_cls',
            'target_anc_idx',
            'target_anc',
            'target_cnt',
          ]
        target_batching: concat
    data_loader:
      batch_size: 16
      num_workers: 2
  test:
    type: coco_detect
    name: test_data
    data_transforms:
      - type: to_tensor
      - type: detect_transform.generate_sparse_anchored_boxcls
        anchor_thr: 2.91
      - type: collect
        inputs: ['img']
        targets:
          [
            'target_cxywh',
            'target_cij',
            'target_cls',
            'target_anc_idx',
            'target_anc',
            'target_cnt',
          ]
        target_batching: concat
    data_loader:
      batch_size: 16
      num_workers: 2
  data_params:
    person_only: true
    input_size: [640, 640]
    input_channels: 3
    num_classes: 80
    anchors:
      - [10, 13, 16, 30, 33, 23] # P3/8
      - [30, 61, 62, 45, 59, 119] # P4/16
      - [116, 90, 156, 198, 373, 326] # P5/32
    strides: [8, 16, 32]

model:
  type: detect_model.yolov5
  backbone:
    type: yolov5_backbone6
    arch:
      layer1: # 640 (hw) => 320 (stride = 2)
        block: conv
        n_channels: 64
        kernel_size: 6
        stride: 2
        padding: 2
      layer2: # 320 => 160 (stride = 4)
        block: conv
        n_channels: 128
        kernel_size: 3
        stride: 2
      layer3: # 160 => 160
        block: c3_bottleneck
        n_inner_blocks: 3
        n_channels: 128
      layer4: # 160 => 80 (stride = 8)
        block: conv
        n_channels: 256
        kernel_size: 3
        stride: 2
      layer5: # 80 => 80
        block: c3_bottleneck
        n_inner_blocks: 6
        n_channels: 256
      layer6: # 80 => 40 (stride = 16)
        block: conv
        n_channels: 512
        kernel_size: 3
        stride: 2
      layer7: # 40 => 40
        block: c3_bottleneck
        n_inner_blocks: 9
        n_channels: 512
      layer8: # 40 => 20 (stride = 32)
        block: conv
        n_channels: 1024
        kernel_size: 3
        stride: 2
      layer9: # 20 => 20
        block: c3_bottleneck
        n_inner_blocks: 3
        n_channels: 1024
      layer10: # 20 => 20
        block: sppf
        n_channels: 1024
        kernel_size: 5
    in_channels: $data.data_params.input_channels
    depth_multiple: 0.33 # model depth multiple
    width_multiple: 0.50 # layer channel multiple
  head:
    type: yolov5_head6
    arch:
      layer1: # 20 (hw) => 20
        block: conv
        n_channels: 512
        kernel_size: 1
        stride: 1
      layer2: # 20 => 40
        block: upsample_layer.upsample
        scale_factor: 2
        mode: 'nearest'
      layer3: # 40 => 40
        block: concat
        input_index: [-1, 6] # backbone layer 7's out
        dim: 1
      layer4: # 40 => 40
        block: c3_bottleneck
        n_inner_blocks: 3
        n_channels: 512
        shortcut: False
      layer5: # 40 => 40
        block: conv
        n_channels: 256
        kernel_size: 1
        stride: 1
      layer6: # 40 => 80
        block: upsample_layer.upsample
        scale_factor: 2
        mode: 'nearest'
      layer7: # 80 => 80
        block: concat
        input_index: [-1, 4] # backbone layer 5's out
        dim: 1
      layer8: # 80 => 80
        block: c3_bottleneck
        n_inner_blocks: 3
        n_channels: 256
        shortcut: False
      layer9: # 80 => 40
        block: conv
        n_channels: 256
        kernel_size: 3
        stride: 2
      layer10: # 40 => 40
        block: concat
        input_index: [-1, 14] # head layer 5's out
        dim: 1
      layer11: # 40 => 40
        block: c3_bottleneck
        n_inner_blocks: 3
        n_channels: 512
        shortcut: False
      layer12: # 40 => 20
        block: conv
        n_channels: 512
        kernel_size: 3
        stride: 2
      layer13: # 20 => 20
        block: concat
        input_index: [-1, 10] # head layer 1's out
        dim: 1
      layer14: # 20 => 20
        block: c3_bottleneck
        n_inner_blocks: 3
        n_channels: 1024
        shortcut: False
      layer15:
        block: yolov5_detect6
        input_index: [17, 20, 23] # head's layer 8, 11, 14 (stride: 8, 16, 32, size: 80, 40, 20)
        anchors: $data.data_params.anchors
        n_classes: $data.data_params.num_classes
        init_cfg:
          input_size: $data.data_params.input_size
          avg_objs: 8
          prob_all_cls: 0.6
    depth_multiple: 0.33 # model depth multiple
    width_multiple: 0.50 # layer channel multiple
  loss:
    type: detect_loss.bbox_obj_cls
    cls_pos_weight: 0.631
    obj_pos_weight: 0.911
    CIoU: true
    layer_obj_weights: [4., 1., 0.4]
    bbox_loss_weight: 0.0296
    obj_loss_weight: 0.301
    cls_loss_weight: 0.243
  predict:
    type: detect_postprocessor.predict
    anchors: $data.data_params.anchors
    conf_thr: 0.25
    iou_thr: 0.45
    max_det: 300
  eval_cfg:
    flip_augment: null # [True, False]
    scale_augment: null # [0.83, 0.67]

optim:
  max_epochs: 300
  optimizer:
    type: sgd
    lr: 0.0032
    weight_decay: 0.00036 # not for bias and batchnorm
    momentum: 0.843
    nesterov: true
    ext_param_groups: [decay_weight, bias]
  lr_scheduler:
    type: cosine_anneal_lr
    min_lr_ratio: 0.12
    warmup: linear
    warmup_ratio: [0.0, 0.0, 10]
    warmup_epochs: 2
    min_warmup_steps: 1000
  momentum_scheduler:
    type: fixed_momentum
    warmup: linear
    warmup_ratio: 0.5
    warmup_epochs: 2
    min_warmup_steps: 1000
  optim_scheduler:
    type: optim

saver:
  interval: 1
  max_keep_ckpts: 5
validator:
  val_at_start: true
summarizer:
  interval: 10
diagnoser:
  at_train_epochs: [1, 10, 20, 50, 90]
  at_train_steps: [1, 10]
  at_val_epochs: [1, 10, 20, 50, 90]
  at_val_steps: [1, 10]
  before_run: [detect.update_model_config]
  before_step: [detect.plot_inputs]
  after_step: [detect.plot_preds]
