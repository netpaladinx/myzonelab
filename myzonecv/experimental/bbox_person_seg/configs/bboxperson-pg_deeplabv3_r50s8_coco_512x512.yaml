data:
  train:
    type: coco_points_guided_bbox_seg
    name: train_data
    data_transforms:
      - type: flip
        flip_map: ['seg_mask']
        flip_coord: ['points']
      - type: lazy_vertical_half
        apply_prob: 0.1
      - type: lazy_horizontal_half
        apply_prob: 0.1
      - type: lazy_translate
        apply_prob: 0.3
      - type: lazy_scale
        apply_prob: 0.3
      - type: lazy_rotate
        apply_prob: 0.3
      - type: warp
        warp_map2d: ['seg_mask']
        warp_coord: ['points']
      - type: albumentations
      - type: agument_hsv
        h_gain: 0.0138
        s_gain: 0.664
        v_gain: 0.464
      - type: seg_transform.points2mask
        sigma_ratio: 0.02
      - type: to_tensor
        tt_map: ['points_mask']
      - type: normalize
      - type: feed_more
        feed_map: ['points_mask']
      - type: seg_transform.generate_target_mask
      - type: collect
        inputs: ['img']
        targets: ['target_mask']
    data_loader:
      batch_size: 16
      num_workers: 2
      shuffle: true
    data_params:
      shuffle: true
  val:
    type: coco_points_guided_bbox_seg
    name: val_data
    data_transforms:
      - type: warp
        warp_map2d: ['seg_mask']
        warp_coord: ['points']
      - type: seg_transform.points2mask
      - type: to_tensor
        tt_map: ['points_mask']
      - type: normalize
      - type: feed_more
        feed_map: ['points_mask']
      - type: collect
        inputs: ['img']
    data_loader:
      batch_size: 16
      num_workers: 2
  infer:
    type: coco_points_guided_bbox_seg
    name: infer_data
    data_transforms:
      - type: warp
        warp_coord: ['points']
      - type: seg_transform.points2mask
      - type: to_tensor
        tt_map: ['points_mask']
      - type: normalize
      - type: feed_more
        feed_map: ['points_mask']
      - type: collect
        inputs: ['img']
    data_loader:
      batch_size: 16
      num_workers: 2
    data_params:
      mode: infer
  data_params:
    input_size: [512, 512]
    input_channels: 3
    output_size: [64, 64] # output stride = 8

model:
  type: seg_model.pointguided_bbox_person
  backbone: # stem conv: 2 stride; stem maxpool: 2 stride; stage 2: 2 stride => 8 stride in total
    type: resnetv1c
    depth: 50
    in_channels: 4
    stem_channels: 64
    base_channels: 64
    n_stages: 4
    strides: [1, 2, 1, 1]
    dilations: [1, 1, 2, 4]
    out_stages: [1, 2, 3, 4]
    deep_stem: true
    contract_first_dilation: true
  decode_head:
    type: seg_head.aspp_head
    in_channels: 2048
    out_channels: 1 # number of classes
    mid_channels: 512
    input_index: 3
    dilations: [1, 12, 24, 36]
    final_dropout: 0.1
    align_corners: false
  auxiliary_head:
    type: seg_head.fcn_head
    in_channels: 1024
    out_channels: 1
    mid_channels: 256
    input_index: 2
    n_convs: 1
    input_shortcut: false
    final_dropout: 0.1
    align_corners: false
  decode_loss:
    type: seg_loss.cross_entropy
    use_sigmoid: true
    loss_weight: 1.0
  auxiliary_loss:
    type: seg_loss.cross_entropy
    use_sigmoid: true
    loss_weight: 0.4
  accuracy:
    type: binary_accuracy
  predict:
    type: seg_postprocess.predict

optim:
  max_epochs: 100
  optimizer:
    type: sgd
    lr: 0.01
    weight_decay: 0.0005 # not for bias and batchnorm
    momentum: 0.9
    nesterov: true
    ext_param_groups: [decay_weight, bias]
  lr_scheduler:
    type: poly_lr
    by_epoch: false
    power: 0.9
    min_lr: 0.0001
  optim_scheduler:
    type: optim

saver:
  interval: 1
  max_keep_ckpts: 5
validator:
  val_at_start: true
summarizer:
  interval: 10
diagnoser:
  # at_train_epochs: [1, 10, 20, 50, 90]
  # at_train_steps: [1, 10]
  # at_val_epochs: [1, 10, 20, 50, 90]
  # at_val_steps: [1, 10]
  # before_run: [detect.update_model_config]
  # before_step: [detect.plot_inputs]
  # after_step: [detect.plot_preds]
